{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import thinkdsp\n",
    "import thinkplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personID</th>\n",
       "      <th>activity</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 33</td>\n",
       "      <td> Jogging</td>\n",
       "      <td> 49105962326000</td>\n",
       "      <td>-0.694638</td>\n",
       "      <td> 12.680544</td>\n",
       "      <td> 0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 33</td>\n",
       "      <td> Jogging</td>\n",
       "      <td> 49106062271000</td>\n",
       "      <td> 5.012288</td>\n",
       "      <td> 11.264028</td>\n",
       "      <td> 0.953424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 33</td>\n",
       "      <td> Jogging</td>\n",
       "      <td> 49106112167000</td>\n",
       "      <td> 4.903325</td>\n",
       "      <td> 10.882658</td>\n",
       "      <td>-0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 33</td>\n",
       "      <td> Jogging</td>\n",
       "      <td> 49106222305000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td> 18.496431</td>\n",
       "      <td> 3.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 33</td>\n",
       "      <td> Jogging</td>\n",
       "      <td> 49106332290000</td>\n",
       "      <td>-1.184970</td>\n",
       "      <td> 12.108489</td>\n",
       "      <td> 7.205164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personID activity            time         x          y         z\n",
       "0        33  Jogging  49105962326000 -0.694638  12.680544  0.503953\n",
       "1        33  Jogging  49106062271000  5.012288  11.264028  0.953424\n",
       "2        33  Jogging  49106112167000  4.903325  10.882658 -0.081722\n",
       "3        33  Jogging  49106222305000 -0.612916  18.496431  3.023717\n",
       "4        33  Jogging  49106332290000 -1.184970  12.108489  7.205164"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/WISDM_ar_v1.1_raw.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbname = ''\n",
    "db = ''\n",
    "\n",
    "for i, (g, gdf) in enumerate(df.groupby('personID')):\n",
    "    # only work with the data for the personID 33\n",
    "    if g==33:\n",
    "        dbname, db = g, gdf\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON 33\n",
      "   personID activity            time         x          y         z\n",
      "0        33  Jogging  49105962326000 -0.694638  12.680544  0.503953\n",
      "1        33  Jogging  49106062271000  5.012288  11.264028  0.953424\n",
      "2        33  Jogging  49106112167000  4.903325  10.882658 -0.081722\n",
      "3        33  Jogging  49106222305000 -0.612916  18.496431  3.023717\n",
      "4        33  Jogging  49106332290000 -1.184970  12.108489  7.205164\n"
     ]
    }
   ],
   "source": [
    "print \"PERSON {}\".format(dbname)\n",
    "print db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pipeline..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dominant_frequency import find_dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dictionary of arrays, where the arrays will be a list of amplitudes for each activity\n",
    "amp_dist = defaultdict(list)\n",
    "domfreq_dist = defaultdict(list)\n",
    "domfreq_dist2 = defaultdict(list)\n",
    "\n",
    "# Groupby the 4 Activites\n",
    "for plotnum, (g, gdb) in enumerate(db.groupby('activity')):\n",
    "    # Calculate Waves\n",
    "    # FIX: framerate is probably not calculated correctly\n",
    "    framerate = 100000\n",
    "    zwave = thinkdsp.Wave(gdb['z'].values, framerate=framerate)\n",
    "    \n",
    "    zwave\n",
    "    start0 = 0\n",
    "    window_size = 0.0003\n",
    "    step_size = window_size / 2\n",
    "    seg_nums = 120\n",
    "    \n",
    "    for i in range(seg_nums):\n",
    "        zseg = zwave.segment(start=start0+i*step_size, duration=window_size)\n",
    "        \n",
    "        # Unbiasing the Wave to make Spectrum amplitude at frequency 0, equal to 0\n",
    "        zseg.unbias()\n",
    "        \n",
    "        # Convert to Frequency Domain\n",
    "        spectrum = zseg.make_spectrum()\n",
    "        \n",
    "        # Extract Peaks\n",
    "        # peak[0] the highest peak\n",
    "        peaks = spectrum.peaks()\n",
    "        \n",
    "        # appending the amplitude of the highest peak to our dictionary of amplitudes for each activity\n",
    "        \n",
    "        # peak[0][0] is the amplitude of the highest peak\n",
    "        # peak[0][1] is the frequency of the highest peak\n",
    "        amp_dist[g].append(peaks[0][0])\n",
    "        domfreq_dist2[g].append(peaks[0][1])\n",
    "        \n",
    "        # dominant frequency\n",
    "        domfreq_dist[g].append(find_dominant(zseg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a check, to see the mean and standard deviation that characterize the distribution of peak amplitude values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking\n",
      "mean amp:  37.0431545312\n",
      "std amp:  8.82675878638\n",
      "mean domfreq:  43497.2527473\n",
      "std domfreq:  42404.6579067\n",
      "mean domfreq2:  22833.3333333\n",
      "std domfreq2:  11663.8885581\n",
      "Jogging\n",
      "mean amp:  51.0915663118\n",
      "std amp:  11.5388338412\n",
      "mean domfreq:  17879.3590669\n",
      "std domfreq:  18868.2820629\n",
      "mean domfreq2:  35638.8888889\n",
      "std domfreq2:  13620.489966\n",
      "Downstairs\n",
      "mean amp:  23.9064234624\n",
      "std amp:  8.66581555018\n",
      "mean domfreq:  24436.7276242\n",
      "std domfreq:  31301.9946498\n",
      "mean domfreq2:  13583.3333333\n",
      "std domfreq2:  10248.4190289\n",
      "Upstairs\n",
      "mean amp:  25.5883485274\n",
      "std amp:  6.18314819799\n",
      "mean domfreq:  18282.4259074\n",
      "std domfreq:  26018.7714273\n",
      "mean domfreq2:  15111.1111111\n",
      "std domfreq2:  5707.91090624\n"
     ]
    }
   ],
   "source": [
    "for (activity, amps), (activity, domfreqs), (activity, domfreqs2) in zip(amp_dist.iteritems(), domfreq_dist.iteritems(), domfreq_dist2.iteritems()):\n",
    "    print activity\n",
    "    print \"mean amp: \",np.array(amps).mean()\n",
    "    print \"std amp: \",np.array(amps).std()\n",
    "    print \"mean domfreq: \", np.array(domfreqs).mean()\n",
    "    print \"std domfreq: \", np.array(domfreqs).std()\n",
    "    print \"mean domfreq2: \", np.array(domfreqs2).mean()\n",
    "    print \"std domfreq2: \", np.array(domfreqs2).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "# dict of gaussian hidden markov models for each activity\n",
    "ghmm = {}\n",
    "\n",
    "# dict of train data for each activity\n",
    "X_train = {}\n",
    "\n",
    "# dict of test data for each activity\n",
    "X_test = {}\n",
    "\n",
    "# number of hidden states\n",
    "n_components = 3\n",
    "\n",
    "# number of samples in the training set\n",
    "train_size = 60\n",
    "\n",
    "# Train a separate GHMM for each activity\n",
    "for activity, amps in amp_dist.iteritems():\n",
    "    # Create GHMM\n",
    "    ghmm[activity] = GaussianHMM(n_components, covariance_type=\"diag\", n_iter=1000)\n",
    "    \n",
    "    # Split into Train and Test Data (No Random Shuffling Now)\n",
    "    # If we wanted to add more features:\n",
    "    # X_train[activity] = np.column_stack([amp_dist[activity][:train_size], next_feature[activity][:train_size])\n",
    "    \n",
    "    features = (amp_dist, domfreq_dist2)\n",
    "\n",
    "    X_train[activity] = np.column_stack([feature[activity][:train_size] for feature in features])\n",
    "    X_test[activity] = np.column_stack([feature[activity][train_size:] for feature in features])\n",
    "    \n",
    "    # Fit on Training Data\n",
    "    # Confused about .fit([X])\n",
    "    ghmm[activity].fit([X_train[activity]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual activity: Walking\n",
      "0\n",
      "predicted activity: Jogging\n",
      "logprobs: \n",
      "{'Walking': -908.01678777656798, 'Downstairs': -2835.7986967145257, 'Jogging': -907.94465196170586, 'Upstairs': -1349.7659876207963}\n",
      "\n",
      "\n",
      "actual activity: Downstairs\n",
      "3\n",
      "predicted activity: Downstairs\n",
      "logprobs: \n",
      "{'Walking': -1020.1666103737786, 'Downstairs': -776.81482303212636, 'Jogging': -1024.372651773861, 'Upstairs': -1190.9363556798253}\n",
      "\n",
      "\n",
      "actual activity: Jogging\n",
      "0\n",
      "predicted activity: Jogging\n",
      "logprobs: \n",
      "{'Walking': -1058.3666544800637, 'Downstairs': -12461.628264153218, 'Jogging': -894.18084333649404, 'Upstairs': -4610.4205010823407}\n",
      "\n",
      "\n",
      "actual activity: Upstairs\n",
      "2\n",
      "predicted activity: Upstairs\n",
      "logprobs: \n",
      "{'Walking': -1104.1912395135478, 'Downstairs': -1497.17352096471, 'Jogging': -972.90500722202, 'Upstairs': -394.13945927885669}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "activities = [\"Jogging\", \"Walking\", \"Upstairs\", \"Downstairs\"]\n",
    "\n",
    "# For each Test Set\n",
    "for activity, X in X_test.iteritems():\n",
    "    print \"actual activity: \" + activity\n",
    "    \n",
    "    # logprobs for each activity_model\n",
    "    # the log-likelihood that the given sequence of observations looks like things this model could produce\n",
    "    logprobs = {}\n",
    "\n",
    "    # Try Out the 4 models\n",
    "    for model_activity, model in ghmm.iteritems():\n",
    "        # model.score returns log likelihood of the observation\n",
    "        logprobs[model_activity] = model.score(X)\n",
    "    \n",
    "\n",
    "    # Which ever has the highest probability will be the model\n",
    "    max_idx = np.argmax(np.array([logprobs[activity] for activity in activities]))\n",
    "    print max_idx\n",
    "    pred_activity = activities[max_idx]\n",
    "    print \"predicted activity: \" + pred_activity\n",
    "    \n",
    "    print \"logprobs: \"\n",
    "    print logprobs\n",
    "    \n",
    "    print \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```n_components``` makes a difference, for classifying between Upstairs and Downstairs.  2 and 4 seem to misclassify, 3 and 5 classify accurately.  \n",
    "- note that the dictionary keys will not be in the same order as the ```activities``` list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODOS:\n",
    "\n",
    "- phone accelerometer\n",
    "    - collect our own dataset\n",
    "- timeseries spacing\n",
    "    - can interpolate given the timestamps\n",
    "- feature visualization / extraction\n",
    "    - frequency bins\n",
    "    - n most dominant frequencies\n",
    "- machine learning pipeline building\n",
    "    - Investigating Assumptions of Training / Evaluation Procedure\n",
    "    - Visualizations of labels versus probability classifications\n",
    "    - Randomized Train Test Split\n",
    "    - Cross Validation (how to determine what's the best ```n_components```\n",
    "    \n",
    "##DONE:\n",
    "\n",
    "- phone accelerometer\n",
    "    - install app\n",
    "- feature visualization / extraction\n",
    "    - timeseries\n",
    "    - frequency spectrum\n",
    "    - power spectrum\n",
    "    - phase\n",
    "    - dominant frequency by autocorrelation\n",
    "- machine learning pipeline building\n",
    "    - Hidden Markov Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
